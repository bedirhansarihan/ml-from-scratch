{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-22T08:57:39.296388Z",
     "start_time": "2024-08-22T08:57:39.291421Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:14.203919Z",
     "start_time": "2024-08-22T08:58:14.198229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(Z: np.array):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "def relu(X: np.array):\n",
    "    A = np.maximum(0, X)\n",
    "    return A\n"
   ],
   "id": "a0aa11b470206f33",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note:** The dataset used in this implementation is sourced from the Deep Learning Specialization.\n",
   "id": "4ebb883987bbf705"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:19.410784Z",
     "start_time": "2024-08-22T08:58:19.404311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File(r'.\\data\\cat_dataset\\train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File(r'.\\data\\cat_dataset\\test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    y_train = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    y_test = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    # Reshape the training and test examples \n",
    "    train_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "    test_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "    \n",
    "    # Standardize data to have feature values between 0 and 1.\n",
    "    X_train = train_x_flatten/255.\n",
    "    X_test = test_x_flatten/255.\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, classes\n",
    "\n"
   ],
   "id": "c034524f18778d85",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:19.621851Z",
     "start_time": "2024-08-22T08:58:19.591134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train, X_test, y_test, _ = load_data()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ],
   "id": "bb87a26ef890b577",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209)\n",
      "(1, 209)\n",
      "(12288, 50)\n",
      "(1, 50)\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Two Hidden Layer Neural Network Implementation\n",
    "\n",
    "In this notebook, we will implement a two-hidden-layer neural network for binary classification problem from scratch using vectorized operations. The steps we will follow include:\n",
    "\n",
    "1. **Parameter Initialization**: Initialize the parameters (weights and biases) for the neural network.\n",
    "2. **Forward Propagation**: Implement the forward propagation step to compute the activations at each layer.\n",
    "3. **Cost Function Computation**: Compute the cost function to measure the model's performance.\n",
    "4. **Backward Propagation**: Implement the backward propagation step to compute gradients with respect to the parameters.\n",
    "5. **Model**: Integrate all functions into a model that can train the neural network using gradient descent.\n",
    "6. **Predict**: Use the trained model to make predictions on new data."
   ],
   "id": "7bdb6b06adbecf49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Parameter Initialization\n",
    "\n",
    "We initialize the parameters for the neural network. The parameters include weights (`W`) and biases (`b`) for each layer. For a neural network with `L` layers (including the input layer, two hidden layers, and the output layer), the parameters will be stored in dictionaries.\n",
    "\n",
    "### Function: `parameter_initialization(layer_dims)`\n",
    "- **Input**: \n",
    "  - `layer_dims` (a list containing the dimensions of each layer in the network, e.g., `[n_x, n_h1, n_h2, n_y]` where `n_x` is the number of input features, `n_h1` and `n_h2` are the number of units in the first and second hidden layers, and `n_y` is the number of output units).\n",
    "  \n",
    "- **Output**: \n",
    "  - `parameters` (a dictionary containing initialized parameters `W` and `b` for each layer).\n",
    "  \n",
    "- **Dimension Constraints**:\n",
    "  - `W[l].shape = (layer_dims[l], layer_dims[l-1])`\n",
    "  - `b[l].shape = (layer_dims[l], 1)`\n",
    "    - "
   ],
   "id": "7a9be62330fbfd70"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:22.317290Z",
     "start_time": "2024-08-22T08:58:22.312580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    def initialize_parameters(layer_dims):\n",
    "        parameters = dict()\n",
    "        \n",
    "        for l in range(1, len(layer_dims)):\n",
    "            parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "            parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "            \n",
    "        return parameters"
   ],
   "id": "9410ce1450df64d8",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:22.824244Z",
     "start_time": "2024-08-22T08:58:22.796481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initalize_parameters_test\n",
    "X_train, _, _, _, _ = load_data()\n",
    "m = X_train.shape[1]\n",
    "layer_dims = (m, 2, 1)\n",
    "\n",
    "parameters = initialize_parameters(layer_dims)\n",
    "print(\"shape of W1: \",parameters['W1'].shape)\n",
    "print(\"shape of b1: \",parameters['b1'].shape)\n",
    "print(\"shape of W2: \",parameters['W2'].shape)\n",
    "print(\"shape of b2: \",parameters['b2'].shape)"
   ],
   "id": "2e1f7b01c7145be5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W1:  (2, 209)\n",
      "shape of b1:  (2, 1)\n",
      "shape of W2:  (1, 2)\n",
      "shape of b2:  (1, 1)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The forward propagation step computes the activations for each layer, starting from the input layer to the output layer. The activation functions used in the layers are ReLU or sigmoid.\n",
    "\n",
    "### Function: `forward_propagation(X, parameters)`\n",
    "- **Input**: \n",
    "  - `X` (input data of shape `(number_of_features, number_of_examples)`)\n",
    "  - `parameters` (a dictionary containing the parameters `W` and `b` for each layer)"
   ],
   "id": "efd0f70c6efab29c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:23.926397Z",
     "start_time": "2024-08-22T08:58:23.921677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ],
   "id": "fbcab4bf1822d0d7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:58:24.730623Z",
     "start_time": "2024-08-22T08:58:24.724733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation_type='relu'):\n",
    "    \n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "    AL = None\n",
    "    \n",
    "    if activation_type == 'relu':\n",
    "        AL = relu(Z)\n",
    "    elif activation_type == 'sigmoid':\n",
    "        AL = sigmoid(Z)\n",
    "    activation_cache = Z\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return AL, cache\n",
    "    \n",
    "    "
   ],
   "id": "4f4670f039073930",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T08:59:42.725578Z",
     "start_time": "2024-08-22T08:59:42.718369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    caches = []\n",
    "    layers_len = len(parameters) // 2\n",
    "    \n",
    "    ###### HIDDEN LAYERS ######\n",
    "    A_prev = X\n",
    "    for l in range(1, layers_len):\n",
    "        \n",
    "        W_l = parameters['W' + str(l)]\n",
    "        b_l = parameters['b' + str(l)]\n",
    "        \n",
    "        A_L, cache = linear_activation_forward(A_prev, W_l, b_l, activation_type='relu')\n",
    "        caches.append(cache)\n",
    "        A_prev = A_L\n",
    "    \n",
    "    ###### OUTPUT LAYER ######\n",
    "    W_l = parameters['W' + str(layers_len)]\n",
    "    b_l = parameters['b' + str(layers_len)]\n",
    "    A_L, cache = linear_activation_forward(A_prev, W_l, b_l, activation_type=\"sigmoid\")  \n",
    "    caches.append(cache)\n",
    "    return A_L, caches\n",
    "        \n",
    "    "
   ],
   "id": "7c1c84ff8cf67482",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-22T09:02:13.276674Z",
     "start_time": "2024-08-22T09:02:13.240491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# forward_propagation_test\n",
    "X_train, _, _, _, _ = load_data()\n",
    "layer_dims = (X_train.shape[0], 2, 1)\n",
    "\n",
    "initial_params = initialize_parameters(layer_dims)\n",
    "A_L, caches = forward_propagation(X_train, parameters=initial_params)\n"
   ],
   "id": "ee18698209f1274a",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5b93f9a9b072340d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
