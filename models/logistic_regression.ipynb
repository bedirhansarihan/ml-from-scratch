{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:06.898318Z",
     "start_time": "2024-08-21T09:17:05.835395Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementing Vectorized Logistic Regression from Scratch\n",
    "\n",
    "In this notebook, we will implement a vectorized version of the logistic regression model from scratch. To facilitate this, it's important to understand the dimensions of the variables involved:\n",
    "\n",
    "### 1. Feature Matrix (`X`)\n",
    "- **Shape**: `(number_of_features, number_of_examples)`\n",
    "- **Description**: This matrix contains the input features of the dataset.\n",
    "\n",
    "### 2. Target Vector (`y`)\n",
    "- **Shape**: `(1, number_of_examples)`\n",
    "- **Description**: This vector contains the target values for each training example.\n",
    "\n",
    "### 3. Weights (`w`)\n",
    "- **Shape**: `(number_of_features, 1)`\n",
    "- **Description**: This vector contains the weights associated with each feature.\n",
    "\n",
    "### 4. Bias (`b`)\n",
    "- **Shape**: Scalar\n",
    "- **Description**: The bias term is a scalar that is added to the weighted sum of the input features to adjust the output.\n"
   ],
   "id": "a86fd6da5bb4acaa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e29728d4e724114d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:09.784707Z",
     "start_time": "2024-08-21T09:17:09.776170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(zero_rank=False, transformed=False):\n",
    "    data = np.loadtxt(r'.\\data\\ex2data1.txt', delimiter=',')\n",
    "\n",
    "    if data.shape[1] > 2:\n",
    "        X = data[:, :-1]\n",
    "        y = data[:, -1]\n",
    "    else:\n",
    "        X = data[:, 0]\n",
    "        y = data[:, 1]\n",
    "    \n",
    "    if not zero_rank:\n",
    "        X = X.reshape(-1, 1) if X.ndim == 1 else X\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    if transformed:\n",
    "        X = X.T\n",
    "        y = y.T\n",
    "    \n",
    "    return X, y\n"
   ],
   "id": "69a90c5d2fc528d9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:10.127012Z",
     "start_time": "2024-08-21T09:17:10.120409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_parameter_with_zeros(X):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param X shape: (nx, number_of_features): \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    n, m = X.shape\n",
    "    \n",
    "    w = np.zeros((n,1))\n",
    "    b = 0.0\n",
    "    return w, b"
   ],
   "id": "ea392abe2dca78c2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:11.204361Z",
     "start_time": "2024-08-21T09:17:11.197063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize_parameter_with_zeros_test\n",
    "X, y = load_data(transformed=True)\n",
    "w, b = initialize_parameter_with_zeros(X)\n",
    "print('w:', w)\n",
    "print('b:', b)"
   ],
   "id": "12ced526d566541c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [[0.]\n",
      " [0.]]\n",
      "b: 0.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:11.526033Z",
     "start_time": "2024-08-21T09:17:11.518922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def logistic_function(X, w, b):\n",
    "    \"\"\"\n",
    "    :param X: shape (number_of_features, number_of_examples) \n",
    "    :param w: shape( number_of_features, 1) \n",
    "    :param b: scalar\n",
    "    :param activation: (linear, sigmoid)\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    z = np.dot(w.T, X ) + b\n",
    "    a = 1/(1 + np.exp(-z))        \n",
    "    return a"
   ],
   "id": "adeea4c12a71fb29",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:12.639982Z",
     "start_time": "2024-08-21T09:17:12.633326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_cost(X, Y, w, b):\n",
    "    \"\"\"\n",
    "    :param X: shape (number_of_features, number_of_examples) \n",
    "    :param Y: shape (1, number_of_examples)\n",
    "    :param w: shape( number_of_features, 1) \n",
    "    :param b: scalar\n",
    "    :return scalar: \n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    Y_hat = logistic_function(X, w, b)\n",
    "    \n",
    "    cost = -np.sum((np.dot(Y, np.log(Y_hat).T) + np.dot(1 - Y, np.log(1 - Y_hat).T))) / m\n",
    "    return cost"
   ],
   "id": "cb84baab497bfbad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:12.933452Z",
     "start_time": "2024-08-21T09:17:12.923854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute_cost_test\n",
    "\n",
    "X,y = load_data(transformed=True)\n",
    "\n",
    "init_w, init_b = initialize_parameter_with_zeros(X)\n",
    "cost = compute_cost(X, y, init_w, init_b)\n",
    "print('Cost at initial w and b (zeros): {:.3f}'.format(cost))"
   ],
   "id": "90d102c6b815eac7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at initial w and b (zeros): 0.693\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:13.456280Z",
     "start_time": "2024-08-21T09:17:13.448533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_gradient(X, Y, w, b):\n",
    "    \"\"\"\n",
    "    :param X: shape (number_of_features, number_of_examples) \n",
    "    :param Y: shape (1, number_of_examples)\n",
    "    :param w: shape( number_of_features, 1) \n",
    "    :param b: scalar\n",
    "    :return tuple (number_of_features, 1), scalar: \n",
    "\n",
    "    \"\"\"\n",
    "    m = X.shape[1]  # number of examples\n",
    "    \n",
    "    Y_hat = logistic_function(X, w, b)\n",
    "\n",
    "    error = Y_hat - Y\n",
    "\n",
    "    db = np.sum(error) / m\n",
    "    dw = np.dot(X, error.T) / m\n",
    "    \n",
    "    return dw, db"
   ],
   "id": "67069f51eec82516",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:13.652650Z",
     "start_time": "2024-08-21T09:17:13.643937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#compute_gradient_test\n",
    "X, y = load_data(transformed=True)\n",
    "init_w, init_b = initialize_parameter_with_zeros(X)\n",
    "\n",
    "dj_dw, dj_db = compute_gradient(X, y, init_w, init_b)\n",
    "print(f'dj_db at initial w and b (zeros):{dj_db}' )\n",
    "print(f'dj_dw at initial w and b (zeros):{dj_dw}' )"
   ],
   "id": "5a358e7e2e262fbf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db at initial w and b (zeros):-0.1\n",
      "dj_dw at initial w and b (zeros):[[-12.00921659]\n",
      " [-11.26284221]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:13.900763Z",
     "start_time": "2024-08-21T09:17:13.893114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_descent(X, Y, w, b, learning_rate=0.01, num_iterations=10000):\n",
    "    costs = []\n",
    "        \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        dw, db = compute_gradient(X, Y, w, b)\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        cost = compute_cost(X, Y, w, b)\n",
    "        costs.append(cost)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: Cost = {cost}\")\n",
    "            # Sonuçları yazdır\n",
    "    print(f\"Final Cost at iteration {num_iterations}:{float(costs[-1]):8.2f}\")\n",
    "    return w, b"
   ],
   "id": "84682a446e22e916",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:15.059499Z",
     "start_time": "2024-08-21T09:17:14.425222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gradient_descent_test\n",
    "X,y = load_data(transformed=True)\n",
    "\n",
    "np.random.seed(1)\n",
    "initial_w = (0.01 * (np.random.rand(2) - 0.5)).reshape(-1,1)\n",
    "initial_b = -8\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "w,b, = gradient_descent(X ,y, initial_w, initial_b, learning_rate=learning_rate, num_iterations=iterations )"
   ],
   "id": "5a797e6092ee0079",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 0.9637901832137513\n",
      "Iteration 1000: Cost = 0.30509032658691554\n",
      "Iteration 2000: Cost = 0.30472280911605276\n",
      "Iteration 3000: Cost = 0.30435770911398763\n",
      "Iteration 4000: Cost = 0.30399500255077383\n",
      "Iteration 5000: Cost = 0.303634665714201\n",
      "Iteration 6000: Cost = 0.3032766752046073\n",
      "Iteration 7000: Cost = 0.3029210079297916\n",
      "Iteration 8000: Cost = 0.3025676411000218\n",
      "Iteration 9000: Cost = 0.3022165522231424\n",
      "Final Cost at iteration 10000:    0.30\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:17:18.699756Z",
     "start_time": "2024-08-21T09:17:18.695100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    :param X: shape (number_of_features, number_of_examples) \n",
    "    :param w: shape( number_of_features, 1) \n",
    "    :param b: scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    y_hat = logistic_function(X, w, b)\n",
    "    \n",
    "    predictions = (y_hat > 0.5).astype(int)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "    "
   ],
   "id": "37d03f62832f453e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T09:18:10.184342Z",
     "start_time": "2024-08-21T09:18:09.558314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#predict_test\n",
    "\n",
    "X_train, y_train = load_data(transformed=True)\n",
    "\n",
    "np.random.seed(1)\n",
    "init_w, init_b = initialize_parameter_with_zeros(X_train)\n",
    "\n",
    "# Some gradient descent settings\n",
    "iterations = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "w,b, = gradient_descent(X ,y, initial_w, initial_b, learning_rate=learning_rate, num_iterations=iterations )\n",
    "preds = predict(X_train, w, b)\n",
    "print(preds)\n"
   ],
   "id": "4da8e32f58f1894a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 0.9637901832137513\n",
      "Iteration 1000: Cost = 0.30509032658691554\n",
      "Iteration 2000: Cost = 0.30472280911605276\n",
      "Iteration 3000: Cost = 0.30435770911398763\n",
      "Iteration 4000: Cost = 0.30399500255077383\n",
      "Iteration 5000: Cost = 0.303634665714201\n",
      "Iteration 6000: Cost = 0.3032766752046073\n",
      "Iteration 7000: Cost = 0.3029210079297916\n",
      "Iteration 8000: Cost = 0.3025676411000218\n",
      "Iteration 9000: Cost = 0.3022165522231424\n",
      "Final Cost at iteration 10000:    0.30\n",
      "[[0 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 1 0 0\n",
      "  1 1 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1\n",
      "  1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 1]]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d8d2d707175fdc6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
